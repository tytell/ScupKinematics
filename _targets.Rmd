---
title: "Target Markdown"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

```{r}
library(targets)
library(tarchetypes)
library(tidyverse)
library(here)
library(arrow)
```

# Setup

This removes the auto-generated `_targets.R` file.

```{r}
tar_unscript()
```

# Globals

We first define some global options/functions common to all targets. 

```{targets global-paths, tar_globals = TRUE}
library(tarchetypes)

options(tidyverse.quiet = TRUE)
tar_option_set(packages = c("tidyverse", "here", "R.utils", "arrow"),
               workspace_on_error = TRUE, # Save a workspace file for a target that errors out.
               format = "parquet"
)
tar_resources_parquet(compression = "snappy")

if (.Platform$OS.type == "unix") {
  videodatapath <- "/Volumes/Data/WHOI-2022/Data from Erik Anderson/TE_WHOI_2022_bottomview/experiments"
  datarootpath <- "/Volumes/DataSync/ScupKinematics/processed_data/experiments"
} else {
  videodatapath <- "Z:\\WHOI-2022\\Data from Erik Anderson\\TE_WHOI_2022_bottomview\\experiments"
  datarootpath <- "Y:\\ScupKinematics\\processed_data\\experiments"
}
#videodatapath <- "/Users/etytel01/Documents/2023/ScupKinematics-old/raw_data/TE_WHOI_2022_bottomview/experiments"
rawdatapath <- "raw_data"
processeddatapath <- "processed_data"

library(cli)
options(cli.progress_show_after = 0)
options(cli.progress_clear = FALSE)

nfilesingroup <- 5

s.frac <- pracma::linspace(0, 1, n = 26)
dt <- 0.02
```

```{targets functions, tar_globals = TRUE}
source("code/scan_raw_files.R")
source("code/midlines.R")
```

# Targets

Matlab script that runs the calibration and generates the `.mat` file that has
the calibration parameters.
```{targets calibration}
list(
  tar_file(calibration_m, here("code", "bottomview_06_16_2022_calib.m")),
  tar_target(calibration, 
             prompt_run_matlab(calibration_m,
                               here("processed_data", 
                                    "TE_WHOI_2022_bottomview/calibrations",
                                    "TE_06_16_2022_1655_calibration.mat")),
             format = "file")
)
```

```{targets triangulate}
list(
  tar_file(filelist, scan_bottomview_files(videodatapath, 
                                         here(processeddatapath, "all_bottomview_files.csv"))),
  tar_file(triangulate_m, "code/triangulate_all_bottomview_data.m"),
  tar_target(data3d, 
             check_matlab_processing(triangulate_m,
                               here(processeddatapath, "processed_bottomview_files.csv"),
                               filelist, calibration),
             format = "file")
)
```

```{targets read_file, tar_globals = TRUE}
read_data_file <- function(datarootpath, filename)
{
  cli::cli_alert_info("Read file {basename(filename)}")
  
  df <- read_csv(file.path(datarootpath, filename), id = "filename",
           col_types = list(.default = col_double()),
           show_col_types = FALSE) |> 
    reorganize_outline_data() |> 
    mutate(filename = factor(filename))
  cli::cli_alert_info("  {nrow(df)} row{?s}")
  df
}
```

```{targets even_outline, tar_globals = TRUE}
even_outline_spacing <- function(df)
{
    df |> 
    ungroup() |> 
    mutate(swimdir =
             purrr::map(outline, \(df) get_central_axis(df, x = xctr, y = yctr),
                        .progress = "Getting central axis...")) |> 
    unnest(swimdir) |> 
    mutate(swimdirx = -swimdirx,
           swimdiry = -swimdiry) |> 
  
    mutate(outline = purrr::pmap(list(df = outline, x = "xctr", y = "yctr", 
                                      a = "m", b = "n",
                                      swimdirx = swimdirx, swimdiry = swimdiry),
                                 rotate_to_swimdir,
                                 .progress = "Rotating to central axis...")) |> 
    mutate(outline = purrr::map(outline, duplicate_head_tail))
}
```

```{targets even_spacing, tar_globals = TRUE}
get_even_spacing <- function(df)
{
  m.max <-
    df |> 
    ungroup() |> 
    mutate(m.max = map_vec(outline, \(df) max(df$m, na.rm = TRUE))) |> 
    summarize(m.max = median(m.max, na.rm = TRUE)) |> 
    pull(m.max)
  
  dm <- m.max / ceiling(m.max / 20)
  m.even <- seq(0, m.max, by = dm)
  
  data.frame(m.even)
}
```


```{targets save_outline_file, tar_globals = TRUE}
save_outline_file <- function(df, filename)
{
  fullfilename <- here(processeddatapath, filename)
  arrow::write_parquet(df, fullfilename,
                compression = "snappy")
  fullfilename
}
```

```{targets getdatafiles}
list(
  tar_file_read(processedfiles, here(processeddatapath, "processed_bottomview_files.csv"),
                read_csv(file = !!.x) |> 
                  mutate(fileexists = map_vec(data3dfile, 
                                              \(f) file.exists(file.path(datarootpath, f))),
                         .progress = "Finding data files")),
  tar_target(testfiles, processedfiles |> 
               filter(isprocessed & fileexists) |> 
               group_by(id) |> 
               mutate(fishgroup = floor(seq(1,n()) / nfilesingroup)) |> 
               filter(id == "scup41"))
)
```

```{r}
processedfiles <- tar_read(processedfiles)
filesummary <-
  processedfiles |> 
  group_by(id) |> 
  summarize(minspeed = min(speed_Hz),
            maxspeed = max(speed_Hz),
            nspeed = length(unique(speed_Hz)))

filesummary
```

```{r}
filesummary |> 
  ungroup() |> 
  summarize(nfish = length(unique(id)),
            across(where(is.numeric), list(mn = mean, sd = sd)))
```
  
```{targets merge3d}
list(
  tar_group_by(filegroup, testfiles, id, fishgroup),
  tar_target(outlinedata1,
             purrr::map_df(filegroup$data3dfile,
                    \(f) read_data_file(datarootpath, f)),
             pattern = map(filegroup),
             error = "continue"),
  tar_target(outlinedata2,
             even_outline_spacing(outlinedata1),
             pattern = map(outlinedata1),
             error = "continue"),
  tar_target(m.even, outlinedata2 |> 
               mutate(filenamedata = process_filename(filename)) |> 
               mutate(fish = pluck(filenamedata, "fish")) |> 
               group_by(fish) |> 
               group_modify(\(df,k) get_even_spacing(df)) |> 
               nest(m.even = m.even)),
  tar_target(outlinedata,
             outlinedata2 |>
               mutate(filenamedata = process_filename(filename),
                      fish = pluck(filenamedata, "fish")) |> 
               left_join(m.even, by = "fish") |> 
               ungroup() |> 
               unnest(outline) |>
               select(-c(xctr, yctr, point)) |>
               arrange(filename, imnum, m) |> 
               nest(edge = c(m,n)) |>
               mutate(edge.even =
                        purrr::map2(edge, m.even, \(df, m.even) interp_even_side(df, m,n, m.even$m.even,
                                                                "pt", names_suffix = ''),
                                   .progress = list(name = "Interpolating even edges",
                                                    format_done = "Total time: {cli::pb_elapsed}",
                                                    clear = FALSE))) |> 
               select(-edge),
             pattern = map(outlinedata2)),
  tar_target(outlinedatafile, 
             save_outline_file(outlinedata, "outlinedata.parquet"),
             format = "file")
)
```


```{targets check_midlines}
list(
  tar_group_by(fishdata, outlinedata, fish),
  tar_target(width, 
             fishdata |> 
               get_width(),
             pattern = map(fishdata)),
  tar_target(data_good,
             fishdata |> 
               remove_bad_frames(width),
             pattern = map(fishdata, width))
)
```

```{targets get_com}
list(
  tar_target(comdata,
             data_good |> 
               select(-c(m.even, filenamedata)) |> 
               get_com(width),
             pattern = map(fishdata, width))
)
```

```{targets interpolate_even}
list(
  tar_group_by(fishcomdata, comdata, fish),
  tar_target(midpoints,   
             get_midline_uneven(fishcomdata),
             pattern = map(fishcomdata)),
  tar_target(evenpoints,
             even_midline_spacing(midpoints, s.frac),
             pattern = map(midpoints)),
  tar_target(evenchunks,
             get_midline_time_chunks(evenpoints, minchunkdur = 2),             
             pattern = map(evenpoints)),
  tar_target(eventime,
             even_midline_timing(evenpoints, evenchunks, dt),
             pattern = map(evenpoints, evenchunks)),
  tar_target(midlinedatafile,
             save_outline_file(eventime, "midlinedata.parquet"),
             format = "file")
  
)
```

# Testing

```{r eval=FALSE}
evenpoints <- tar_read(evenpoints, branches = 1)
evenchunks <- tar_read(evenchunks, branches = 1)
```

```{r eval=FALSE}
even_midline_timing(evenpoints, evenchunks, dt)
```

```{r eval=FALSE}
midpoints <- tar_read(midpoints, branches = 1)

even1 <-
  midpoints |> 
  group_by(filename, imnum) |> 
  mutate(ds1 = sqrt((m - lag(m))^2 + (mid - lag(mid))^2),
         ds1 = replace_na(ds1, 0),
         s1 = cumsum(ds1)) |> 
  select(-ds1) |> 
  group_by(fish, filename, imnum) |> 
  nest(midline = c(pt, s1,m,mid)) |> 
  ungroup() |> 
  mutate(mid.even = purrr::map(midline, \(df) even_points(df, s1,m,mid, s.frac),
                               .progress = TRUE))
```

```{r eval=FALSE}
head(even1)
even1$midline[[1]]
```

```{r}
tar_read(evenpoints, branch = 1) |> 
  ungroup() |> 
  distinct(speedHz)
```

```{r}
tar_read(evenpoints, branch = 1) |> 
  get_midline_time_chunks(maxchunkgap = 0.04, minchunkdur = 2) |> 
  ungroup() |> 
  distinct(speedHz)

```

```{r}
tar_read(evenchunks) |> 
  ungroup() |> 
  distinct(speedHz) |> 
  arrange(speedHz)
```

# Pipeline

```{r eval=FALSE}
tar_visnetwork()
```

If you ran all the `{targets}` chunks in non-interactive mode, then your R scripts are set up to run the pipeline.

```{r eval=FALSE}
tar_make()
```


